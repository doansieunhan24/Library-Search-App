"""
M√≥dulo x·ª≠ l√Ω t√¨m ki·∫øm s√°ch th√¥ng minh
K·∫øt h·ª£p speech-to-text, text correction, SQL generation v√† database query
"""

import os
import sqlite3
import torch
import torchaudio
from transformers import WhisperProcessor, WhisperForConditionalGeneration
import re
import logging
from config import (
    DATABASE_PATH, 
    WHISPER_MODEL_NAME, 
    WHISPER_MODEL_PATH,
    OPENAI_API_KEY,
    MAX_SEARCH_RESULTS,
    LOG_LEVEL
)

# Try to import OpenAI, with fallback
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError as e:
    print(f"Warning: OpenAI not available: {e}")
    OPENAI_AVAILABLE = False
    OpenAI = None

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SearchProcessor:
    """L·ªõp x·ª≠ l√Ω t√¨m ki·∫øm s√°ch th√¥ng minh"""
    
    def __init__(self, database_path=None, model_path=None, openai_api_key=None):
        """
        Kh·ªüi t·∫°o SearchProcessor
        
        Args:
            database_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn database SQLite
            model_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn Whisper model
            openai_api_key (str): API key cho OpenAI
        """
        # Database connection
        self.database_path = database_path or DATABASE_PATH
        self.conn = None
        self.init_database()
        
        # Whisper model
        self.model_path = model_path or WHISPER_MODEL_PATH
        self.processor = None
        self.model = None
        self.init_whisper_model()
        
        # OpenAI client
        self.openai_api_key = openai_api_key or OPENAI_API_KEY
        self.openai_client = OpenAI(api_key=self.openai_api_key)
    
    def init_database(self):
        """Kh·ªüi t·∫°o k·∫øt n·ªëi database"""
        try:
            self.conn = sqlite3.connect(self.database_path, check_same_thread=False)
            logger.info(f"ƒê√£ k·∫øt n·ªëi database: {self.database_path}")
        except Exception as e:
            logger.error(f"L·ªói k·∫øt n·ªëi database: {e}")
            self.conn = None
    
    def init_whisper_model(self):
        """Kh·ªüi t·∫°o Whisper model"""
        try:
            model_name = WHISPER_MODEL_NAME
            self.processor = WhisperProcessor.from_pretrained(model_name)
            
            if self.model_path and os.path.exists(self.model_path):
                self.model = WhisperForConditionalGeneration.from_pretrained(self.model_path)
                logger.info(f"ƒê√£ t·∫£i model t·ª´: {self.model_path}")
            else:
                self.model = WhisperForConditionalGeneration.from_pretrained(model_name)
                logger.info(f"ƒê√£ t·∫£i model m·∫∑c ƒë·ªãnh: {model_name}")
            
            self.model.generation_config.language = "vi"
            self.model.generation_config.task = "transcribe"
            self.model.generation_config.forced_decoder_ids = None
            
        except Exception as e:
            logger.error(f"L·ªói kh·ªüi t·∫°o Whisper model: {e}")
            self.processor = None
            self.model = None
    
    def load_audio(self, audio_path):
        """
        Load v√† preprocessing audio file
        
        Args:
            audio_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file audio
            
        Returns:
            torch.Tensor: Audio waveform ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
        """
        try:
            waveform, sample_rate = torchaudio.load(audio_path)
            
            # Resample to 16kHz if needed
            if sample_rate != 16000:
                resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)
                waveform = resampler(waveform)
            
            return waveform.squeeze()
        except Exception as e:
            logger.error(f"L·ªói load audio: {e}")
            return None
    
    def transcribe_audio(self, audio_path):
        """
        Chuy·ªÉn ƒë·ªïi audio th√†nh text s·ª≠ d·ª•ng Whisper
        
        Args:
            audio_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file audio
            
        Returns:
            str: Text ƒë√£ ƒë∆∞·ª£c chuy·ªÉn ƒë·ªïi
        """
        try:
            if not self.processor or not self.model:
                return "L·ªói: Model ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o"
            
            # Load audio
            audio = self.load_audio(audio_path)
            if audio is None:
                return "L·ªói: Kh√¥ng th·ªÉ load audio"
            
            # Process audio
            inputs = self.processor(audio, sampling_rate=16000, return_tensors="pt")
            
            # Generate transcription
            with torch.no_grad():
                predicted_ids = self.model.generate(inputs["input_features"])
            
            # Decode
            transcription = self.processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]
            
            logger.info(f"Transcription: {transcription}")
            return transcription.strip()
            
        except Exception as e:
            logger.error(f"L·ªói transcribe audio: {e}")
            return f"L·ªói nh·∫≠n di·ªán: {str(e)}"
    
    def correct_text(self, text):
        """
        S·ª≠a l·ªói ch√≠nh t·∫£ v√† ng·ªØ ph√°p s·ª≠ d·ª•ng OpenAI
        
        Args:
            text (str): VƒÉn b·∫£n c·∫ßn s·ª≠a
            
        Returns:
            str: VƒÉn b·∫£n ƒë√£ ƒë∆∞·ª£c s·ª≠a l·ªói
        """
        try:
            if not text or text.strip() == "":
                return text
            
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system", 
                        "content": "H√£y s·ª≠a l·ªói ch√≠nh t·∫£, ng·ªØ ph√°p n·∫øu c√≥ c·ªßa t·ª´ng t·ª´ trong vƒÉn b·∫£n ti·∫øng Vi·ªát ƒë·∫ßu v√†o m√† ng∆∞·ªùi d√πng cung c·∫•p. Ch·ªâ tr·∫£ v·ªÅ vƒÉn b·∫£n ƒë√£ ƒë∆∞·ª£c ch·ªânh s·ª≠a, kh√¥ng th√™m d·∫•u c√¢u, kh√¥ng lo·∫°i b·ªè t·ª´, n·∫øu nh·∫≠n di·ªán t·ª´ ƒë·∫ßu v√†o kh√¥ng h·ª£p ng·ªØ c·∫£nh v√† kh√¥ng t√¨m ƒë∆∞·ª£c t·ª´ thay th·∫ø, gi·ªØ nguy√™n t·ª´ ƒë√≥, v√† kh√¥ng th√™m b·∫•t k·ª≥ th√¥ng tin n√†o kh√°c."
                    },
                    {"role": "user", "content": text}
                ],
                max_tokens=150,
                temperature=0.1
            )
            
            corrected_text = response.choices[0].message.content.strip()
            logger.info(f"Text correction: '{text}' -> '{corrected_text}'")
            return corrected_text
            
        except Exception as e:
            logger.error(f"L·ªói correct text: {e}")
            return text  # Tr·∫£ v·ªÅ text g·ªëc n·∫øu c√≥ l·ªói
    
    def text_to_sql(self, text):
        """
        Chuy·ªÉn ƒë·ªïi vƒÉn b·∫£n th√†nh SQL query s·ª≠ d·ª•ng OpenAI
        
        Args:
            text (str): VƒÉn b·∫£n y√™u c·∫ßu t√¨m ki·∫øm
            
        Returns:
            str: SQL query
        """
        try:
            system_prompt = """H√£y chuy·ªÉn vƒÉn b·∫£n ti·∫øng Vi·ªát ƒë·∫ßu v√†o m√† ng∆∞·ªùi d√πng cung c·∫•p th√†nh d·∫°ng SQL query ƒë·ªÉ truy xu·∫•t d·ªØ li·ªáu c·ªßa s√°ch, v·ªõi c√°c thu·ªôc t√≠nh c·ªßa database:
            
            T√™n b·∫£ng: books
            C√°c c·ªôt: ['id', 'title', 'author', 'publisher', 'publication_year', 'pages', 'dimensions', 'registration_number', 'price', 'storage_location', 'document_type', 'availability', 'keywords', 'subject', 'department', 'summary', 'url']
            
            V√≠ d·ª• v·ªÅ d·ªØ li·ªáu: [1, 'Qu√°n vƒÉn 110 : chuy√™n ƒë·ªÅ vƒÉn h·ªçc ngh·ªá thu·∫≠t', 'Nguy√™n Minh (ch.b)', 'H·ªôi Nh√† vƒÉn', 2024, '333 tr.', '21 cm.', 56245, 200000, '03 Quang Trung', 'S√°ch Tham Kh·∫£o', '10/10', 'qu√°n vƒÉn', 'VƒÉn h·ªçc ngh·ªá thu·∫≠t', 'Bao g·ªìm c√°c b√†i vi·∫øt...', 'https...']
            
            L∆∞u √Ω: 
            - Ch·ªâ ƒë∆∞·ª£c ph√©p tr·∫£ l·ªùi SQL query
            - S·ª≠ d·ª•ng LIKE '%keyword%' cho t√¨m ki·∫øm t·ª´ kh√≥a
            - S·ª≠ d·ª•ng LOWER() ƒë·ªÉ kh√¥ng ph√¢n bi·ªát hoa th∆∞·ªùng
            - Gi·ªõi h·∫°n k·∫øt qu·∫£ b·∫±ng LIMIT {MAX_SEARCH_RESULTS}"""
            
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": text}
                ],
                max_tokens=200,
                temperature=0.1
            )
            
            sql_query = response.choices[0].message.content.strip()
            
            # Clean up SQL query
            sql_query = sql_query.replace("```sql", "").replace("```", "").strip()
            
            logger.info(f"Generated SQL: {sql_query}")
            return sql_query
            
        except Exception as e:
            logger.error(f"L·ªói text to SQL: {e}")
            return "SELECT * FROM books LIMIT 10;"  # Default query
    
    def query_database(self, sql_query):
        """
        Th·ª±c hi·ªán truy v·∫•n database
        
        Args:
            sql_query (str): SQL query
            
        Returns:
            tuple: (success: bool, results: list ho·∫∑c error_message: str)
        """
        try:
            if not self.conn:
                return False, "Kh√¥ng c√≥ k·∫øt n·ªëi database"
            
            cursor = self.conn.cursor()
            cursor.execute(sql_query)
            rows = cursor.fetchall()
            
            if len(rows) == 0:
                return True, []
            
            # Get column names
            column_names = [description[0] for description in cursor.description]
            
            # Convert to list of dictionaries
            results = []
            for row in rows:
                result_dict = dict(zip(column_names, row))
                results.append(result_dict)
            
            logger.info(f"Database query returned {len(results)} results")
            return True, results
            
        except Exception as e:
            error_msg = f"L·ªói truy v·∫•n database: {str(e)}"
            logger.error(error_msg)
            return False, error_msg
    
    def format_search_results(self, results):
        """
        Format k·∫øt qu·∫£ t√¨m ki·∫øm ƒë·ªÉ hi·ªÉn th·ªã
        
        Args:
            results (list): Danh s√°ch k·∫øt qu·∫£ t·ª´ database
            
        Returns:
            str: K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c format
        """
        if not results:
            return "‚ùå KH√îNG T√åM TH·∫§Y S√ÅCH PH√ô H·ª¢P\n\nVui l√≤ng th·ª≠ l·∫°i v·ªõi t·ª´ kh√≥a kh√°c."
        
        formatted_text = f"üìö T√åM TH·∫§Y {len(results)} CU·ªêN S√ÅCH:\n\n"
        
        for i, book in enumerate(results, 1):
            formatted_text += f"üîπ S√ÅCH {i}:\n"
            formatted_text += f"   üìñ T√™n: {book.get('title', 'N/A')}\n"
            formatted_text += f"   ‚úçÔ∏è T√°c gi·∫£: {book.get('author', 'N/A')}\n"
            formatted_text += f"   üè¢ NXB: {book.get('publisher', 'N/A')}\n"
            formatted_text += f"   üìÖ NƒÉm: {book.get('publication_year', 'N/A')}\n"
            formatted_text += f"   üìÑ Trang: {book.get('pages', 'N/A')}\n"
            formatted_text += f"   üí∞ Gi√°: {book.get('price', 'N/A')} VNƒê\n"
            formatted_text += f"   üìç V·ªã tr√≠: {book.get('storage_location', 'N/A')}\n"
            formatted_text += f"   üè∑Ô∏è Lo·∫°i: {book.get('document_type', 'N/A')}\n"
            formatted_text += f"   ‚úÖ T√¨nh tr·∫°ng: {book.get('availability', 'N/A')}\n"
            
            if book.get('keywords'):
                formatted_text += f"   üîç T·ª´ kh√≥a: {book.get('keywords')}\n"
            
            formatted_text += "\n" + "‚îÄ" * 50 + "\n"
        
        return formatted_text
    
    def process_search_request(self, audio_path):
        """
        X·ª≠ l√Ω to√†n b·ªô request t√¨m ki·∫øm t·ª´ audio
        
        Args:
            audio_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file audio
            
        Returns:
            tuple: (transcribed_text: str, formatted_results: str)
        """
        try:
            # Step 1: Transcribe audio
            transcribed_text = self.transcribe_audio(audio_path)
            if "L·ªói" in transcribed_text:
                return transcribed_text, "‚ùå Kh√¥ng th·ªÉ x·ª≠ l√Ω audio"
            
            # Step 2: Correct text
            corrected_text = self.correct_text(transcribed_text)
            
            # Step 3: Convert to SQL
            sql_query = self.text_to_sql(corrected_text)
            
            # Step 4: Query database
            success, results = self.query_database(sql_query)
            
            if not success:
                return transcribed_text, f"‚ùå L·ªñI T√åM KI·∫æM:\n{results}"
            
            # Step 5: Format results
            formatted_results = self.format_search_results(results)
            
            return transcribed_text, formatted_results
            
        except Exception as e:
            error_msg = f"‚ùå L·ªñI X·ª¨ L√ù: {str(e)}"
            logger.error(error_msg)
            return "L·ªói x·ª≠ l√Ω", error_msg
    
    def test_connection(self):
        """Test t·∫•t c·∫£ c√°c k·∫øt n·ªëi"""
        status = {
            "database": False,
            "whisper": False,
            "openai": False
        }
        
        # Test database
        try:
            if self.conn:
                cursor = self.conn.cursor()
                cursor.execute("SELECT COUNT(*) FROM books LIMIT 1")
                status["database"] = True
        except:
            pass
        
        # Test Whisper
        status["whisper"] = self.processor is not None and self.model is not None
        
        # Test OpenAI
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": "test"}],
                max_tokens=5
            )
            status["openai"] = True
        except:
            pass
        
        return status
    
    def close(self):
        """ƒê√≥ng k·∫øt n·ªëi"""
        if self.conn:
            self.conn.close()
            logger.info("ƒê√£ ƒë√≥ng k·∫øt n·ªëi database")

# Example usage
if __name__ == "__main__":
    # Test the SearchProcessor
    processor = SearchProcessor()
    
    # Test connections
    status = processor.test_connection()
    print("Connection status:", status)
    
    # Test text processing
    test_text = "T√¨m s√°ch Python"
    corrected = processor.correct_text(test_text)
    sql = processor.text_to_sql(corrected)
    success, results = processor.query_database(sql)
    
    print(f"Original: {test_text}")
    print(f"Corrected: {corrected}")
    print(f"SQL: {sql}")
    print(f"Results: {len(results) if success else 'Error'}")
    
    processor.close()
